\documentclass[12pt]{article}
\usepackage{amsmath, amsthm, amssymb, amsfonts}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{float}
\usepackage{xcolor}

\DeclareMathOperator*{\argmin}{argmin}

%opening
\title{Flat Norm on Graphs}
\author{Sandy Auttelet, Jared Brannan, Blake Cecil, Curtis Michels,\\
 Katrina Sabochick, Kevin Vixie }

\begin{document}

\maketitle

\begin{abstract}
In this paper we implement and test a method for computing the multiscale flat norm signature for characteristic functions over irregular grids in $\mathbb{R}^2$ and $\mathbb{R}^3$.
\end{abstract}

\tableofcontents

\section{Multiscale Flat Norm}

In 2005, Chan and Esedoglu introduced an edge preserving total variation regularization functional:

\begin{equation} \label{ce}
F_{CE}(u) = \int_\Omega |\nabla u| dx + \lambda \int_{\Omega} |u-f|dx
\end{equation}

Where $\Omega$ is a domain on which we have greyscale data $f:\Omega \to \mathbb{R}$ we would like to denoise. Solving the associated minimization problem above we obtain:

\begin{align*}
u^* = \argmin_u F_{CE}(u)
\end{align*}

Which is the denoised greyscale approximation $u^*:\Omega \to \mathbb{R}$ to the data $f$. The strength of the denoising may be adjusted by the parameter $\lambda \in [0,\infty)$, a large value of $\lambda$ corresponds to enacting a stricter penalty for candidates $u$ that deviate too far from the original data and thus enforce less denoising. We henceforth refer to (\ref{ce}) as the $L^1$TV functional.

It was recognized in \cite{Morgan_2007} by Simon Morgan and Kevin Vixie that the $L^1$TV functional was both a special case of and an extension of the flat norm in geometric measure theory (GMT). Work was done in \cite{shapes} by Kevin Vixie Et al. to explore the implications of this.


\section{Discrete Implementations}

Let $\chi_E$ is the characteristic function of $E$, with $\chi_E(x) = 1$ if $x \in E$ and $0$ otherwise, then $u$ may be taken to be of this form, and the $L^1$TV functional in (\ref{ce}) reduces to:

\begin{align*}
F_{CE}(\Sigma) &= \text{Per}(\Sigma) + \lambda|\Sigma \Delta \Omega|
\end{align*}

Where $\Sigma$ is the support of $u = \chi_\Sigma$, Per($\Sigma$) is the perimeter of $\Sigma$, and $\Sigma \Delta \Omega$ is the symmetric difference between $\Sigma$ and the support $\Omega$ of the data $f = \chi_\Omega$. 

The flat norm with scale $\lambda$ of an oriented $1$-dimensional set $T$ is given by:

\begin{equation} \label{fn}
\mathbb{F}(T) = \min_S \{V_1(T-\partial S) + \lambda V_2(S)\}
\end{equation}

Where $V_1$ is 1-dimensional volume (length), $V_2$ is 2-dimensional volume (area) and $S$ varies over $2$-dimensional regions. We refer to the pair of the 1D and 2D sets $\{T,S\}$ as the flat norm decomposition. By \cite{Morgan_2007} we have for fixed $\lambda$:

\begin{equation}
\mathbb{F}(\partial \Omega) = F_{CE}(\Sigma)
\end{equation}

with flat norm decomposition $\{\partial \Omega, \Sigma \Delta \Omega\}$, with $\partial \Omega$ denoting the measure theoretic boundary of $\Omega$. In \cite{shapes}, Vixie Et al. thus represented the problem of computing the flat norm as minimizing the $L^1$TV functional and computing the minimzer by graph cuts as introduced by \cite{kolmogorov}. Applied to images, this is realized by representing each pixel as a node on a rectangular grid which forms the working space. A characteristic function $\chi_\Omega$ is defined on the nodes which represents a black and white thresholded image. Graph edges are added between each node using 16 nearest neighbors in image space. Each of these edges are weighted by minimizing gradient computation error on known functions. After, a virtual sink ($t$) and a virtual source node ($s$) are added. The source node is connected to every node in $\Omega$ and the sink to every node on the grid not in $\Omega$. 

A particular cut of this graph has a capacity equal to the value of the flat norm $\mathbb{F}(S)$ for a set of nodes $S$ consisting of nodes $n$ for which either the edge $(n,s)$ or $(n,t)$ is in the cut. Any cut of the graph incurs a penalty proportional to the number of image nodes it cuts, with the penalty exactly equal to $V_1(T-\partial S)$ in (\ref{fn}) for parameter $\lambda$. Hence finding a cut with minimal capacity is the same as computing the flat norm. 

The vector of weights $w^*$ calculated in \cite{shapes} were chosen more specifically to approximate the function $g_\theta:\mathbb{R}^2 \to \mathbb{R}$ whose gradient is $\nabla g_\theta = (\cos \theta, \sin \theta)^T$ for all $\theta$:

\begin{equation} \label{oldmin}
w^* = \argmin_w \int_0^{2\pi} (h(w,\theta)-1)^2 d\theta
\end{equation}

With

\begin{align*}
h(w,\omega) &= \sum_{j=1}^4 w_1 |\nabla g_\theta \cdot v_j| + \sum_{j=5}^8 w_2 |\nabla g_\theta \cdot v_j| +  \sum_{j=9}^{16} w_3 |\nabla g_\theta \cdot v_j|
\end{align*}

Where $v_j, j= 1,...,16$ are the vectors from a fixed point in the grid to its 16 nearest neighbors, where three types of neighbor groupings are identified as below.

\begin{figure}[H]
\centering
\includegraphics[scale=0.25]{Figure_2_Vixie_Paper.png}
\caption{16 vector neighborhood from \cite{shapes}.}
\end{figure}

Equation (\ref{oldmin}) was solved analytically to obtain weights $(w_1,w_2,w_3) \approx (0.1221,0.0476,0.0454)$. 


\section{Flat Norm on Arbitrary 2D and 3D Graphs}

In the present work, we extend the multiscale flat norm computation to arbitrary graphs embedded in $\mathbb{R}^n$ using the framework above, and provide code to calculate explicitly in $\mathbb{R}^2$ and $\mathbb{R}^3$.

Let $V = \{v_1,...,v_N\}$ be a set of vertices in $\mathbb{R}^n$ with a set of symmetric edges $E$ on $V$. Fix a particular vertex $v \in V$ with degree $D$ and associated connections $\{u_i, i = 1,...,D\}$. We will provide a scheme for calculating the edge weights $\{w_i, i = 1,...,D\}$ that recover the weights obtained in (\ref{oldmin}) in the case of a regular unit grid and extend to arbitrary irregular grids and connections. Our weights will be chosen to minimize the distance (in the $L^2$ sense) between the linear approximation of a weighted sum of the edges and the total variation over $\partial B(0,1)$, the unit sphere at the origin:

\begin{align}
\mathcal{F}(w_1,w_2,...,w_D) := \int_{\partial B(0,1)} \left|\sum_{i=1}^D w_i |\langle \nu, u_i \rangle| - \| \nu \| \right|^2d\nu
\end{align}

Which expands into the quadratic:

\begin{align*}
\mathcal{F}(w_1,w_2,...,w_D) &= \sum_{i=1}^D w_i^2C_1^i + 2 \sum_{i=1}^D \sum_{j=1}^{i-1} w_i w_j C_3^{ij} - 2 \sum_{i=1}^D w_i C_2^i + \alpha(n)
\end{align*}

Where $\alpha(n) = \int_{\partial B(0,1)}d\nu$ is the $n$-dimensional measure of the unit $n$ sphere, with:

\begin{align*}
C_1^i &:= \int_{\partial B(0,1)} |\langle \nu,u_i \rangle|^2 d\nu\\
C_2^i &:= \int_{\partial B(0,1)} |\langle \nu,u_i \rangle| d\nu\\
C_3^{ij} &:= \int_{\partial B(0,1)} |\langle \nu,u_i \rangle \langle \nu, u_j \rangle| d\nu
\end{align*}

\textcolor{red}{The function above is convex, and thus we minimize it by calculating the gradient}:

\begin{align*}
	\frac{\partial \mathcal{F}}{\partial \omega_k}  &= 2 \omega_k C_1^k + 2 \sum_{m=1}^{D}\omega_{m}C_{3}^{km} - 2\omega_kC_3^{kk} - 2 C_2^k\\
\end{align*}

Which forms a linear system of $D$ equations in $D$ unknowns. \textcolor{red}{WLOG this system may be presumed nonsingular, as if two edges $u_n$ and $u_m$ are linearly dependent, by scaling and symmetry they will receive the same weight and thus one may be safely removed from the calculation.} Thus we can simply solve our system for the stationary point:

\begin{align*}
2 \omega_1 C_1^1 + 2 \sum_{m=2}^{D}\omega_{m}C_{3}^{1m}  - 2 C_2^1 &= 0\\
\vdots \hspace{20mm} & \\
2 \omega_D C_1^D + 2 \sum_{m=1}^{D-1}\omega_{m}C_{3}^{Dm} - 2 C_2^D &= 0\\
\end{align*}

If needed, the Hessian may also be quickly calculated:

\begin{align*}
\frac{\partial^2 \mathcal{F}}{\partial \omega_k \partial \omega_\ell} &= \begin{cases}
2C_1^k & \text{ if } \ell = k\\
2C_3^{k\ell} & \text{ otherwise}
\end{cases}
\end{align*}

Thus the problem reduces to calculation of $C_1^i$, $C_2^i$ and $C_3^{ij}$. We provide the following table of values:

\begin{figure}[H]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
 &  2D  & 3D  \\
\hline
 $C_1^i$ & $\pi \| u_i \|^2$  & $\frac{4\pi}{3}\|u_i\|^2$   \\
\hline
 $C_2^i$ & $4\| u_i \|$  & $2\pi \|u_i\|$    \\
\hline
 $C_3^{ij}$ & Numerical  & Numerical    \\
\hline
\end{tabular}
\end{figure}

Solving this system produces a weight $w_i$ for each edge $u_i$ for the vertex $v$, in order to approximate the total variation integral in (5) we multiply each weight by the area of its associated Voronoi cell. With the weighted graph we can then apply the Min Cut Max Flow algorithm after connecting vertices to the virtual source and sink as previously described. 


\section{Tests}

Being the conveyer of intuition, we provide some examples. First an image is converted into a greyscale representation using the characteristic function previously described 

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.25]{circlepic.png}
	\hspace{2em}
	\includegraphics[scale=0.35]{circlesgraph2.png}
	\caption{Representation of a image as a set of points in $\mathbb{R}^2$, blue points are then used as vertices in the graph.}
\end{figure}

Each pixel in the image is thresholded to produce a greyscale version, the pixels passing the threshold are then converted in to cartesian coordinates which represent the embedding of the graph in $\mathbb{R}^2$. 

In practice the complete graph is created using these nodes and then pruned down to the nearest neighbors, with 24 being used for the results here. Using the previously described algorithm we can then compute the flatnorm for these graphs using the points colored in blue as $\Omega$ and the full image as the background set $\Sigma$. The flat norm with scale provides a bounded curvature approximation to the set $\Omega$ according to the choice of $\lambda$. Our circle example highlights that $\lambda$ large we will be able to reconstruct the set exactly but as $\lambda$ becomes smaller, circles of radius $r$ with curvature $1 / r > \lambda$ will begin to disappear in the reconstruction.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{circleslamb.png}
	\caption{The flat norm reconstruction of the image, as lambda decreases higher curvature regions are removed.}
\end{figure}


An added benefit of the assignment of the weights to the graph is the ability to then compute the perimeter of $\Omega$. This is achieved by summing up the weights of edges that cross from $\Omega$ into the background image $\Sigma$. We do this in 2D and 3D for the circle and sphere respectively, and get the following approximations.

\begin{figure}[H]
	\centering
	\begin{tabular}{|c|c|c|c|}
		\hline
		&  Grid Size & Perimeter Estimate Relative Error  \\
		\hline
		$\mathbb{S}^1$ & 30x30 &  2.6\%  \\
		\hline
		$\mathbb{S}^2$ & TBD & TBD    \\
		\hline
	\end{tabular}
\end{figure}

\section{Edge Cases}

A limitation of the current approach is that for sets $\Omega$ sufficiently close to the boundary of the image pathological behavior occurs.



\bibliographystyle{plain} % We choose the "plain" reference style
\bibliography{refs} % Entries are in the refs.bib file

\end{document}
